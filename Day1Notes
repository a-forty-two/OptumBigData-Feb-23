
Big Data Ecosystem- on premise v/s Cloud


Day 1: Big Data Ecosystem (ETL v/s ELT)
Day 2: PySpark and Scala (Notebooks)
Day 3: Data Pipelines (Apache Beam/Data Factory)
					- Batch (Data Warehouses) v/s Stream (Kafta & Storm)
Day 4: Data Analysis and EDA 
Day 5: Big Data ML (PySpark or Scala) [0.5 day]




- Code-ful : PySpark and Scala (SQL)
- CodeLess: 
            - Azure: Data Factory, Synapse Pipelines 
            - GCP: Data Fusion 

- Apache Beam (ETL) 
- Spark: theory 

- Tool Based: Code + codeless (Machine Learning, Data Analysis) 




Big Data-> data that is TOO BIG for 1 machine!

Machine’s capacity = 2 numbers! 

1, 2 and 3 -> big data!

OLTP/SQL/MySQL/FS:

M1-> 1, 2					—— replication ———   M3->.   1,2
M2-> 3														  M4-> 3

3 numbers = 4 machines!!!


Sharding : (OLAP) [Collossus File System]

Tablet -> 3 shards! [HADOOP]-> HDFS

M1-> 1, 2				M2-> 2, 3				M3-> 3, 1


3 numbers= 3 machines!


Big data-> SHARDING!


Fault Domain: no 2 machine sets will be unavailable at the same time!






Problem: edit 2 into 4!
Assumption: every ops takes 1ms!

M1-> 1, 2					—— replication ———   M3->.   1,2
M2-> 3														  M4-> 3


			1st			2ms				3ms

M1		NF			Found		Replace (2->4)		= 5ms (TOTAL CONSUMPTION!)
M2		NF			-



M1-> 1, 2				M2-> 2, 3				M3-> 3, 1

			1st			2ms				3ms

M1		NF			Found			Replace		= 8ms (TOTAL CONSUMPTION)
M2		Found		Replace		NF
M3		NF			NF				-


Problem: search for 2!
Assumption: every ops takes 1ms!

M1-> 1, 2					—— replication ———   M3->.   1,2
M2-> 3														  M4-> 3


			1ms			2ms			3ms			4ms…	
M1		NF			FOUND									= FASTEST= 2ms; total= 3ms
M2		NF			-



M1-> 1, 2				M2-> 2, 3				M3-> 3, 1

			1st			2ms			3ms….
M1		NF
M2		FOUND												= FASTEST= 1ms; total= 3ms
M3		NF


EDIT-> OLTP
SEARCH-> OLAP


NoSQL Databases Created:

1. Document Style: MongoDB 
        1. BSON: Binary Script Object Notation 
                1. { “name”: “Pikachu”, “age”: 23, “hobbies”: [ { }, { },…..] }
        2. JSON - Information Interchange (NOT STORAGE)
        3.  XML 

2. Table (COLUMN oriented): HIVE, HBase, BigQuery, SQL DW, ….

Idx 	Name		Age		Hobby
1		Pikachu		23		Sleeping -> file1
2		Jason		23		Reading	-> file2
3		Pikachu		42		Reading	-> file3
4		Random	42		Sleeping 	-> file4

File system-> (IDX, FName)
in columnar datastores:
Every column is a separate file!!!
Name-> { 1: Pikachu, 2: Jason, 3: Pikachu, 4: Random…}
Age->	{1: 23, 2: 23, 3: 42, 4: 42}
Hobby-> {….}

Dictionary Encoding: {keys becomes values; values become keys!}

Name: { Pikachu: [1,3], Jason: [2], Random: [4]}
Age-> {23: [1, 2], 42: [3,4]}
Hobby-> {sleeping: [1,4], reading: [2,3]}


HBase-> 2 applications: Gmail (BigTable), Outlook and Google Analytics!!!

Analytics-> SEARCH, NO EDITING
Transactions-> EDITING, No SEARCHING!

3. Graph Databases: Both transaction and analytics
		Each node in the graph-> transactional
		Graph itself-> Analytical

any changes-> NO CHANGES ARE MADE~!!!!! [ALL BIG DATA SYSTEM!]
		-> new node is created; previous one removed from the graph



BFS, DFS (breadth first, depth first search)
									


